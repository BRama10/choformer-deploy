task: "train" # train, test, benchmarking (to be set up later)
dna_fm_id: "zhihan1996/DNABERT-2-117M" # pretrained dna foundation model id for huggingface

decoder_model:
  protein_embedding_size: 
  decoder_size:
  dna_seq_len:
  dna_model_path: 
  layers: 6
  heads: 8
  dropout: 0.1

decoder_hparams:
  beta1: 
  beta2: 
  num_epochs: 10
  lr: 5e-4


lstm_model:
  input_size: 768
  hidden_size: 384
  num_layers: 2

lstm_train:
  batch_size: 16
  n_epochs: 10
  grad_accum_iter: 4
  grad_clip: 5.0
  epochs_per_val: 1
  learning_rate: 3e-3
  weight_decay: 1e-3
  beta_1: 0.9
  beta_2: 0.999
  ckpt_path: ""

data:
  train_data_path: "data/rna/rna_normalized.csv"
  val_data_path: "data/rna/rna_normalized.csv"
  fasta_path: "data/rna/rna_expression_seqs"
  batch_size: 32
  num_workers: 8
  max_length: 1024 # max sequence length to truncate/pad to

log:
  project: explstm
  name: test_run
  ckpt_path: "."